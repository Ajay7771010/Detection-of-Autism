{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southwest-profession",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-study",
   "metadata": {},
   "source": [
    "Identification of Autism using magnetic Resonance Imaging A NOVEL APPROACH COMBINING CONVOLUTIONAL NEURAL NETWORK  & Ensemble Learning (CNN-EL) compared with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quantitative-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model,Sequential,load_model,Input\n",
    "\n",
    "from keras.applications import MobileNet,MobileNetV2,InceptionV3\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.layers import AveragePooling2D,Flatten,Dense,Dropout,MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import img_to_array,load_img\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-alexandria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autistic', 'non_autistic']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "understanding-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "label=[]\n",
    "for i in ['train','test']:\n",
    "    for j in os.listdir(i):\n",
    "        for z in os.listdir(f'{i}/{j}'):\n",
    "            img=load_img(f'{i}/{j}/{z}',target_size=(64,64))\n",
    "            img1=img_to_array(img)\n",
    "            data.append(img1.flatten())\n",
    "            label.append(j)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "framed-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(data)\n",
    "y=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "searching-cherry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2836, 12288)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2836,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cellular-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signal-crown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn=neighbors.KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amateur-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train Score 0.7235543018335684\n",
      "The Test Score 0.607898448519041\n"
     ]
    }
   ],
   "source": [
    "print('The Train Score',knn.score(x_train,y_train))\n",
    "print('The Test Score',knn.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-preserve",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "increasing-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2536 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rotation_range=20,zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15,\n",
    "                             horizontal_flip=True,fill_mode=\"nearest\")\n",
    "\n",
    "train_data=datagen.flow_from_directory('train/',target_size=(299,299),class_mode=\"categorical\",batch_size=64)\n",
    "\n",
    "\n",
    "test_data=datagen.flow_from_directory('test/',target_size=(299,299),class_mode=\"categorical\",batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "smooth-tongue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autistic': 0, 'non_autistic': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "closed-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_model=InceptionV3(weights='imagenet',include_top=False,input_tensor=Input(shape=(299,299,3)))\n",
    "\n",
    "top_model=bot_model.output\n",
    "top_model=MaxPooling2D(pool_size=(7,7))(top_model)\n",
    "top_model=Flatten()(top_model)\n",
    "top_model = Dense(128, activation=\"relu\")(top_model)\n",
    "top_model = Dropout(0.5)(top_model)\n",
    "top_model = Dense(2, activation=\"softmax\")(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recent-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_model = Model(inputs=bot_model.input, outputs=top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "scheduled-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in bot_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "weird-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = Adam(lr=0.0001, decay=0.0001 /20)\n",
    "fin_model.compile(loss=\"categorical_crossentropy\", optimizer=opti,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "grateful-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\projectmain\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/95 [===========>..................] - ETA: 3:15 - loss: 47.6973 - accuracy: 0.5048WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1900 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 38 batches). You may need to use the repeat() function when building your dataset.\n",
      "95/95 [==============================] - 168s 2s/step - loss: 41.1357 - accuracy: 0.5150 - val_loss: 6.2342 - val_accuracy: 0.6633\n"
     ]
    }
   ],
   "source": [
    "history = fin_model.fit_generator(train_data,steps_per_epoch=3066 //32,\n",
    "                    validation_data=test_data,validation_steps=767//20,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aggregate-devil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non_autistic'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=np.array(['autistic','non_autistic'])\n",
    "image=load_img('test/non_autistic/126.jpg',target_size=(299,299))\n",
    "img=img_to_array(image)\n",
    "ex_im=np.expand_dims(img,axis=0)\n",
    "class2=fin_model.predict(ex_im)\n",
    "names[np.argmax(class2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-lodging",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
